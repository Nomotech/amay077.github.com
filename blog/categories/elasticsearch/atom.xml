<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: elasticsearch | Experiments Never Fail]]></title>
  <link href="http://blog.amay077.net/blog/categories/elasticsearch/atom.xml" rel="self"/>
  <link href="http://blog.amay077.net/"/>
  <updated>2016-10-16T19:55:52+09:00</updated>
  <id>http://blog.amay077.net/</id>
  <author>
    <name><![CDATA[amay077]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Elasticsearch の Auto-Rebalancing を Docker で試す]]></title>
    <link href="http://blog.amay077.net/blog/2014/08/06/trying-auto-rebalancing-by-elasticsearch-on-docker/"/>
    <updated>2014-08-06T23:39:51+09:00</updated>
    <id>http://blog.amay077.net/blog/2014/08/06/trying-auto-rebalancing-by-elasticsearch-on-docker</id>
    <content type="html"><![CDATA[<p>Linuxど素人の Docker 入門第二弾です。
ちょっと Docker おもしろくなってきたかも。</p>

<!--more-->


<p><a href="http://www.elasticsearch.org/">Elasticsearch</a> というのは、Apache Solr と並ぶ（むしろ Solr より流行ってきた？）全文検索システムなんですが、複数のサーバにデータを分散配置して並列処理やフェイルオーバーができたりします。</p>

<p>んで、Auto-Rebalancing というのは、サーバ（ノードというらしい）を追加した時に、そのサーバの役割が自動的に決まって、他のサーバからデータを分けて貰って、全体としてデータの平衡化が行われる事です。</p>

<p>Docker なら、サーバーの起動が容易なので、Auto-Rebalancing を試すのに持ってこいだと思い、やってみました。</p>

<p>全体的には、</p>

<ul>
<li><a href="http://inokara.hateblo.jp/entry/2013/11/15/042752">elasticsearch と elasticsearch-head を docker でサクッと試す &ndash; ようへいの日々精進 XP</a></li>
</ul>


<p>を参考にしています。</p>

<h2>ubuntu の Docker コンテナに Elasticsearch をインストール</h2>

<p><a href="http://blog.amay077.net/blog/2014/08/05/docker-try-first/">昨日</a>使った ubuntu のコンテナに Elasticsearch をインストールします。</p>

<p>Elasticsearch のインストールは、</p>

<ul>
<li><a href="https://gist.github.com/wingdspur/2026107">Install ElasticSearch on Ubuntu 12.04</a></li>
</ul>


<p>を参考にしました。（なんか Elasticsearch を導入済みのコンテナとか Dockerfile もあったみたい）</p>

<p>次に、Elasticsearch の管理GUIを提供するプラグイン elasticsearch-head を導入します。</p>

<p>elasticsearch-head については、こちらがとても参考になりました。</p>

<ul>
<li><a href="http://yuheikagaya.hatenablog.jp/entry/2013/07/14/185752">elasticsearchのGUI「elasticsearch-head」がとても便利 &ndash; yuhei.kagaya</a></li>
</ul>


<p>インストールは、以下のコマンド一発です。(./ を付けないとうまく動いてくれなかった)</p>

<p><code>sh
[ root@bb638d1f825f:/ ]$ cd elasticsearch/bin
[ root@bb638d1f825f:/ ]$ ./plugin -install mobz/elasticsearch-head
</code></p>

<h2>Elasticsearch のクラスタの設定</h2>

<p>複数の Elasticsearch を動かす場合、共通のグループ名を付ける必要があります。</p>

<p><code>elasticsearch.yml</code> を編集して、グループ名を付けます。</p>

<p><code>
[ root@bb638d1f825f:/ ]$ vim elasticsearch/config/elasticsearch.yml
</code></p>

<p><code>json elasticsearch.yml
cluster.name: amaycluster
</code></p>

<p>Elasticsearch の分散環境での使用については、</p>

<ul>
<li><a href="http://dev.classmethod.jp/cloud/aws/use-elasticsearch-2-use-cluster/">Cluster機能を使う – AWSで始めるElasticSearch(2) ｜ Developers.IO</a></li>
</ul>


<p>を参考にしました。
「EC2ではマルチキャストが使えない」などと書かれていますが、これは Docker なのでスルーで。結果的には <code>elasticsearch.yml</code> は上記の修正しかしていません。</p>

<h2>Elasticsearch 設定済のイメージを作る</h2>

<p>ここまでで一旦コンテナを終了し、<code>docker commit</code> で保存します。
<code>docker images</code> でイメージが作成できたのが確認できます。</p>

<p>```sh
docker@boot2docker:~$ docker commit -m &ldquo;Setting Elasticsearch cluster&rdquo; bb638d1f825f amay077/es_cluster</p>

<p>docker@boot2docker:~$ docker images
REPOSITORY                 TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
amay077/es_cluster         latest              b9d05b77d71a        9 hours ago         1.075 GB
ubuntu                     latest              ba5877dc9bec        2 weeks ago         192.7 MB
```</p>

<h2>複数の Docker コンテナを起動し、それぞれで Elasticsearch を起動する</h2>

<p>下のようなコマンドで、コンテナを起動し、Elasticsearch を開始します。
（<code>/bin/bash</code> の代わりに直接 elasticsearch を開始してもよいと思いますが、後で直接コンソールに接続したいかなーと思いまして。）</p>

<p>```sh
docker@boot2docker:~$ docker run -i -t -p 9200:9200 -p 9300:9300 amay077/es_cluster /bin/bash</p>

<p>[ root@bb638d1f825f:/ ]$ /elasticsearch/bin/elasticsearch -d</p>

<h1>Control+p, Control+q でデタッチ</h1>

<p>```</p>

<p>1つ起動した時点で、ホストPC（Mac）のブラウザから <a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a> にアクセスします。
あ、その前に VirtualBox の設定で、9200と9300のポートフォワーディングを行う必要があります。</p>

<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/trying-auto-rebalancing-by-elasticsearch-on-docker_04.png" alt="" /></p>

<p>設定できたら先のアドレスにアクセスすると elasticsearch-head の管理画面が表示されるはずです。</p>

<p>続いて、さっきのコマンドを複数回実行し、複数の Elasticsearch を起動します。
<code>-p 9200:9200</code> のところが重複するとエラーになるので <code>-p 9201:9200</code> などとズラしましたが、これで正しかったのかわかりません。</p>

<h2>Elasticsearch にデータ投入</h2>

<p>Elasticsearch へのデータ投入は、ホストPC（Mac）の Terminal から、</p>

<p><code>sh
curl -XPOST 'http://localhost:9200/mytest/memo/' -d '{ "name" : "kappa", "date" : "2013-09-07", "message" : "test1" }'
curl -XPOST 'http://localhost:9200/mytest/memo/' -d '{ "name" : "kappa", "date" : "2013-09-07", "message" : "test2" }'
curl -XPOST 'http://localhost:9200/mytest/memo/' -d '{ "name" : "kappa", "date" : "2013-09-07", "message" : "test3" }'
…続く
</code></p>

<p>のような感じで、3万件ほど投入しました。</p>

<p>投入後、 <a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a> を見ると、</p>

<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/trying-auto-rebalancing-by-elasticsearch-on-docker_01.png" alt="" /></p>

<p>となっています。４台のサーバにデータが分散して登録されたことが分かります。四角内の数字（0〜4）は、「データが5つに分割され」て、その「ブロックがどのサーバに配置されているか」を示していて、太枠がプライマリ、細枠がスレーブであることを示しています。
いずれのサーバが死んでも、データの欠損なくサービス継続できることを示しています。</p>

<h2>ノードを追加してみる</h2>

<p>５台目の Elasticsearh を追加してみます。</p>

<p>```sh
docker@boot2docker:~$ docker run -i -t -p 9204:9200 -p 9304:9300 amay077/es_cluster /bin/bash</p>

<p>[ root@de6d825fa34d:/ ]$ /elasticsearch/bin/elasticsearch -d</p>

<h1>Control+p, Control+q でデタッチ</h1>

<p>```</p>

<p>その後 elasticsearch-head を見ると、</p>

<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/trying-auto-rebalancing-by-elasticsearch-on-docker_01.png" alt="" /></p>

<p>となり、しばらくしてから Refresh すると、</p>

<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/trying-auto-rebalancing-by-elasticsearch-on-docker_03.png" alt="" /></p>

<p>となります。</p>

<p>追加された「Isaiah Bradley」サーバには、データブロック１と３のスレーブの役割が与えられ、データが移動されたことが分かります。（移動中は色が変わったけどスクショ撮れなかった）</p>

<p>このように Elasticsearch の Auto-Rebalancing を、Docker を使うことでお手軽に試すことができました。（実運用では Elasticsearch に Docker は、、、使わないですよねたぶん）</p>

<iframe src="http://rcm-fe.amazon-adsystem.com/e/cm?lt1=_blank&bc1=000000&IS2=1&bg1=FFFFFF&fc1=000000&lc1=0000FF&t=oku2008-22&o=9&p=8&l=as4&m=amazon&f=ifr&ref=ss_til&asins=4048662023" style="width:120px;height:240px;" scrolling="no" marginwidth="0" marginheight="0" frameborder="0"></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[総務省のデータを Elasticsearch にぶち込んで、緯度経度から市区町村の何丁目までを取り出す]]></title>
    <link href="http://blog.amay077.net/blog/2013/09/10/implementing-reverse-geocoding-using-elasticsearch/"/>
    <updated>2013-09-10T21:13:00+09:00</updated>
    <id>http://blog.amay077.net/blog/2013/09/10/implementing-reverse-geocoding-using-elasticsearch</id>
    <content type="html"><![CDATA[<p>いわゆる「逆ジオコーディング」と呼ばれる機能ですが、きっかけはこれら２つの記事です。</p>

<!--more-->


<ul>
<li><a href="http://qiita.com/hamichamp/items/ac9e80f1078febb9f1b9">PHP &ndash; 総務省のデータを使って、緯度経度から市区町村の何丁目までを取り出す</a></li>
<li><a href="http://qiita.com/masuidrive/items/21a282c7bf54fd6a4985">PostgreSQL &ndash; 国土交通省のデータを使って、緯度経度から市区町村までを取り出す</a></li>
</ul>


<p>Solr や Elasticsearch でも同じことができるのでは、という事で Elasticsearch でやってみました。</p>

<h2>Elasticsearch の導入</h2>

<p>は、</p>

<ul>
<li><a href="http://amay077.github.io/blog/2013/09/09/using-spatialdata-with-elasticsearch/">Elasticsearch で位置情報を検索する手順 &ndash; Experiments Never Fail</a></li>
</ul>


<p>をご覧ください。</p>

<h2>1. 総務省のデータをダウンロードする</h2>

<ul>
<li><a href="http://qiita.com/hamichamp/items/ac9e80f1078febb9f1b9">PHP &ndash; 総務省のデータを使って、緯度経度から市区町村の何丁目までを取り出す</a></li>
</ul>


<p>とほぼ同じですが、「世界測地系緯度経度・G-XML形式」ではなく、 <strong>「世界測地系緯度経度・shape形式」</strong> を使います。</p>

<p>一応再掲すると、</p>

<ol>
<li><a href="http://e-stat.go.jp/SG2/eStatGIS/page/download.html">http://e-stat.go.jp/SG2/eStatGIS/page/download.html</a> へ行く。</li>
<li>左から「平成22年度国勢調査（小地域）」を選ぶ。</li>
<li>「男女別人口総数及び世帯総数」（←なんでもいい）を選択して、「統計表各種データダウンロードへ」を押す。</li>
<li>「世界測地系緯度経度・Shape形式」のデータ（下図参照）をダウンロードする。ダウンロードしたら zip ファイルのまま置いといて。</li>
</ol>


<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/implementing_reverse_geocoding_using_elasticsearch_01.png" alt="img" /></p>

<h2>2. Shapefile を GeoJSON 形式に変換する</h2>

<p>Elasticsearch へ投入できるデータ形式は JSON なので、ダウンロードした Shape形式のデータを JSON 形式の地理空間拡張である GeoJSON 形式に変換します。</p>

<p>スクリプトを書いてもできますが面倒なので、便利なオンラインツールに頼ることにします。</p>

<ul>
<li><a href="http://converter.mygeodata.eu/#convertVector">Free on-line GIS data format and coordinates converter</a></li>
</ul>


<p>手順は、</p>

<ol>
<li>上記サイトへ行き、「Run vector converter」を押す。</li>
<li>「ファイルを選択」で、さっきダウンロードした ZIP ファイルを指定し、「Send ZIP File」を押す。</li>
<li>&ldquo;Datasets description&rdquo; というページになったら、その最下部にある「Chack available operations」を押す。(ここでは、不要なデータ項目を除外できるのだけど、面倒なので割愛)</li>
<li>”Export to format:” で &ldquo;GeoJSON&rdquo; を選択。それ以外はそのままで「Proceed selected operation」を押す。</li>
<li>しばらく待つと、「Download the ZIP file」リンクが表れるので、押して変換結果をダウンロードする。</li>
</ol>


<p>ダウンロードした ZIP ファイルを解凍すると、「xxx.json」ファイルが見つかります。それをテキストエディタで開くと、<code>features</code> 以下に、住所エリアの情報が1行ずつ出力されています。</p>

<p>試しに1行取り出して、JSON を整形（見やすいよう適宜省略）してみると次のようになります。</p>

<p>```javascript town.json
{</p>

<pre><code>"type": "Feature",
"properties": {
    "KEN_NAME": "愛知県", 
    "GST_NAME": "名古屋市", 
    "CSS_NAME": "中区", 
    "MOJI": "本丸", 
    …省略…
}, 
"geometry": {
    "type": "Polygon",
    "coordinates": [
        [[136.895888, 35.187236], 
         [136.897375, 35.187357], 
          …中略… 
         [136.895888, 35.187236]]
    ]
}
</code></pre>

<p>}
```</p>

<p>これは「愛知県名古屋市中区本丸」のデータですね。
<code>properties</code> 以下は、この住所エリアの属性情報を示しています。
<code>geometry</code> 以下が、この住所エリアの位置情報（ポリゴン）を示しています。</p>

<h2>3. Elasticsearch にスキーマを定義する</h2>

<p>Elasticseach はスキーマフリーですが、位置情報のところだけは明示的に宣言しないといけないらしいので、下のようなコマンドを実行して定義します。</p>

<p>あ、ここでは、</p>

<ul>
<li>Index名 : towns</li>
<li>Type名 : town</li>
</ul>


<p>としています。</p>

<p>「Index や Type って何？」という方は</p>

<ul>
<li><a href="http://qiita.com/ise_daisuke/items/5e10e0b3ef9dffed08a9">Elasticsearch用語の適当なまとめ</a></li>
</ul>


<p>をどうぞ。</p>

<p>ではコマンドです。</p>

<p>```sh
curl -XPUT &lsquo;<a href="http://localhost:9200/towns/">http://localhost:9200/towns/</a>&rsquo;</p>

<p>curl -XPUT &lsquo;<a href="http://localhost:9200/towns/town/_mapping">http://localhost:9200/towns/town/_mapping</a>&rsquo; -d &lsquo;
{</p>

<pre><code>"town" : {
    "properties": {
        "geometry": {
            "type": "geo_shape", 
            "tree": "quadtree",
            "precision": "1m"
        }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<p><code>properties.geometry</code> は、「geo_shape」 として扱う事を宣言しています。他の２つの設定は、インデックスの種類と精度を意味しますが、よく分かってません。</p>

<ul>
<li><a href="http://www.elasticsearch.org/guide/reference/mapping/geo-shape-type/">Geo Shape Type | Reference Guide | Elasticsearch</a></li>
</ul>


<p>で勉強しましょう。</p>

<h2>4. データを Elasticsearch に投入する</h2>

<p>さて、いよいよこの「1行1JSON」のデータを、1行ずつ、Elasticsearch に投入します。
先の xxxx.json を置換なり何なりを駆使して、スクリプトにしちゃうのがてっとり早いでしょう。(json ファイルは Shift-jis なので、UTF-8 に変換しておきましょう。）</p>

<p>1行のデータを投入するコマンドは次のようになります。</p>

<p>```
curl -XPUT &lsquo;<a href="http://localhost:9200/towns/town/1">http://localhost:9200/towns/town/1</a>&rsquo; -d &lsquo;{</p>

<pre><code>"type": "Feature",
"properties": {
    "KEN_NAME": "愛知県", 
    "GST_NAME": "名古屋市", 
    "CSS_NAME": "中区", 
    "MOJI": "本丸", 
    …省略…
}, 
"geometry": {
    "type": "Polygon",
    "coordinates": [
        [[136.895888, 35.187236], 
         [136.897375, 35.187357], 
          …中略… 
         [136.895888, 35.187236]]
    ]
}
</code></pre>

<p>}&lsquo;
```</p>

<p><code>towns/town/1</code> の最後の「1」のところは、連番にする必要があります。(オートインクリメントとかないのかな？)</p>

<p>全件を PUT すつスクリプトファイルは、下の画像のような感じになると思います。(データのライセンスがどうか分からないのでスクリプトファイル自体を公開するのはやめておきます)</p>

<p><img src="https://dl.dropboxusercontent.com/u/264530/qiita/implementing_reverse_geocoding_using_elasticsearch_02.png" alt="img" /></p>

<p>これをTerminal で実行すると、数分かからずに Elasticsearch にデータが投入完了します。</p>

<p><code>curl -XGET 'http://localhost:9200/towns/town/1'</code> などを実行すれば、正しくデータが登録できたか確認できます。</p>

<h2>5. 検索してみる</h2>

<p>ついに来ました。
では、緯度経度を与えて住所が返ってくるところ、やってみましょう。</p>

<p>Elasticsearch では検索クエリも JSON で書きます。</p>

<p>例えば、<a href="http://yahoo.jp/zsXYL2">大須観音駅</a> らへんの緯度経度(35.1613077,136.898282)の住所で検索する場合は、次のようにします。</p>

<p>```
curl -XPOST &lsquo;<a href="http://localhost:9200/towns/town/_search">http://localhost:9200/towns/town/_search</a>&rsquo; -d &lsquo;{</p>

<pre><code>"query": {
    "filtered" : {
        "query" : {
            "match_all" : {}
        },
        "filter" : {
             "geo_shape": {
                "town.geometry": {
                    "shape": {
                        "type" : "envelope",
                        "coordinates" : [[136.898282, 35.1613077], [136.898282, 35.1613077]]
                    }
                }
            }
        }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<p><code>geo_shape</code> フィルタを使い、条件に envelople(左上〜右下の領域) を指定します。今は「点」での検索をしたいので、左上、右下に同じ座標を指定します。
注意点は、 <strong>「経度, 緯度」</strong> の順であることです。</p>

<p>※ <a href="http://www.elasticsearch.org/guide/reference/query-dsl/geo-distance-filter/"><code>geo_distance</code></a> というフィルタもありますが、こちらはデータが「点」専用なようで、今回のような「ポリゴン」には使えませんでした。</p>

<p>さて、上のコマンドを実行すると、下のような結果が得られます。(整形、省略済)</p>

<p>```
{
  &ldquo;took&rdquo;:1,
  &ldquo;timed_out&rdquo;:false,
  &ldquo;_shards&rdquo;:{</p>

<pre><code>"total":5,
"successful":5,
"failed":0
</code></pre>

<p>  },
  &ldquo;hits&rdquo;:{</p>

<pre><code>"total":1,
"max_score":1.0,
"hits":[{
  "_index":"towns",
  "_type":"town",
  "_id":"29",
  "_score":1.0, 
  "_source" : { 
    "type": "Feature", 
    "properties": { 
      "KEN_NAME": "愛知県", 
      "GST_NAME": "名古屋市", 
      "CSS_NAME": "中区", 
      "MOJI": "大須２丁目", 
      …以下省略…
</code></pre>

<p>```</p>

<p>はい、「緯度経度(35.1613077,136.898282)」の住所は「愛知県名古屋市中区大須２丁目」であることが取得できました。</p>

<h2>まとめ</h2>

<p>いかがでしょうか、Elasticsearch でも逆ジオコーディングの実装が、簡単にできることが分かりました。</p>

<p>PostGIS、MongoDB との対比では、</p>

<ul>
<li>セットアップが簡単</li>
<li>REST API なので直接他のサービスとマッシュアップできる</li>
</ul>


<p>あたりがメリットでしょうか。</p>

<p>逆にデータの取り込みはひと工夫必要で、PostGIS の方が簡単です。
このデータ用の River plugin を作ればよいのでしょうが、方法がさっぱり…。</p>

<p>最後に、</p>

<p><a href="http://qiita.com/hamichamp/items/ac9e80f1078febb9f1b9">総務省のデータを使って、緯度経度から市区町村の何丁目までを取り出す</a></p>

<blockquote><p>実は、データをダウンロードするのが、一番手間がかかります・・・。</p></blockquote>

<p>でも言われていますが、まったくその通りです。
１市区町村ずつダウンロードとか正直やってられません。</p>

<p>総務省でも国土交通省でもどちらでも良いのですが、
<strong>「全国の大字境界＋属性データを一括入手する方法」</strong> を用意して欲しいものです。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch で位置情報を検索する手順]]></title>
    <link href="http://blog.amay077.net/blog/2013/09/09/using-spatialdata-with-elasticsearch/"/>
    <updated>2013-09-09T21:08:00+09:00</updated>
    <id>http://blog.amay077.net/blog/2013/09/09/using-spatialdata-with-elasticsearch</id>
    <content type="html"><![CDATA[<p>Elasticsearch は、オープンソースの全文検索エンジンです。Apache Solr と並んでよく取り上げられるようになってきました。</p>

<p>位置情報の検索機能も標準搭載しているとのことで、試しに使ってみました。</p>

<!--more-->


<h2>Elasticsearch の導入</h2>

<p>下の情報が大変参考になりました。(環境は Mac。事前に Java と homebrew の導入が必要です）</p>

<ul>
<li><a href="http://qiita.com/Konboi@github/items/56f0aaca77db5df027af">elasticsearch &ndash; ElasitcSearch ことはじめ &ndash; Qiita [キータ]</a></li>
</ul>


<h2>試しに使ってみる</h2>

<p>下のサイトが大変参考なりました。</p>

<ul>
<li><a href="http://inokara.hateblo.jp/entry/2013/09/07/153826">Elasticsearch を試してみる &ndash; ようへいの日々精進</a></li>
</ul>


<h2>位置情報を検索してみる</h2>

<p>下のようなスキーマのデータを登録して検索する想定です。</p>

<p>```javascript venue_example.json
{</p>

<pre><code>"name" : "Tokyo St",
"pin" : {
    "location" : {
        "lat" : 35.68,
        "lon" : 139.76
    }
}
</code></pre>

<p>}
```</p>

<h3>1. スキーマを登録する</h3>

<p>Elasticsearch は基本的にはスキーマレスで動くのですが、位置情報を表す項目は、明確にスキーマを定義する必要があるようです。</p>

<p>データ投入の前にそれを行います。</p>

<p>```sh
curl -XPUT &lsquo;<a href="http://localhost:9200/myvenues/">http://localhost:9200/myvenues/</a>&rsquo;</p>

<p>curl -XPUT &lsquo;<a href="http://localhost:9200/myvenues/venue/_mapping">http://localhost:9200/myvenues/venue/_mapping</a>&rsquo; -d &lsquo;
{</p>

<pre><code>"venue" : {
    "properties" : {
        "pin" : { "type" : "geo_point" }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<p>ここでは、<code>venue</code> のプロパティ群の内の <code>pin</code> 項目は、位置情報(geo_point)だよ、と定義しています。</p>

<h3>2. データを投入する</h3>

<p>2件ほど、テストデータを投入します。</p>

<p>```sh
curl -XPUT &lsquo;<a href="http://localhost:9200/myvenues/venue/1">http://localhost:9200/myvenues/venue/1</a>&rsquo; -d &lsquo;{</p>

<pre><code>"name" : "Tokyo St",
"tag" : ["station", "train"],
"pin" : {
    "location" : {
        "lat" : 35.68,
        "lon" : 139.76
    }
}
</code></pre>

<p>}'</p>

<p>curl -XPUT &lsquo;<a href="http://localhost:9200/myvenues/venue/2">http://localhost:9200/myvenues/venue/2</a>&rsquo; -d &lsquo;{</p>

<pre><code>"name" : "Nagoya St",
"tag" : ["station", "train"],
"pin" : {
    "location" : {
        "lat" : 35.17,
        "lon" : 136.88
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<h3>3. 位置情報で検索する</h3>

<h4>位置＋距離</h4>

<p>緯度/経度:35.6/139.8 から 20km 周囲にあるデータを検索します。</p>

<p>```sh
curl -XPOST &lsquo;<a href="http://localhost:9200/myvenues/venue/_search">http://localhost:9200/myvenues/venue/_search</a>&rsquo; -d &lsquo;{</p>

<pre><code>"query": {
    "filtered" : {
        "query" : {
            "match_all" : {}
        },
        "filter" : {
            "geo_distance" : {
                "distance" : "20km",
                "venue.pin" : {
                    "lat" : 35.6,
                    "lon" : 139.8
                }
            }
        }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<h5>結果</h5>

<p>Tokyo St だけがヒットしました。</p>

<p>```javascript
{&ldquo;took&rdquo;:0,&ldquo;timed_out&rdquo;:false,&ldquo;<em>shards&rdquo;:{&ldquo;total&rdquo;:5,&ldquo;successful&rdquo;:5,&ldquo;failed&rdquo;:0},&ldquo;hits&rdquo;:{&ldquo;total&rdquo;:1,&ldquo;max_score&rdquo;:1.0,&ldquo;hits&rdquo;:[{&ldquo;</em>index&rdquo;:&ldquo;myvenues&rdquo;,&ldquo;<em>type&rdquo;:&ldquo;venue&rdquo;,&ldquo;</em>id&rdquo;:&ldquo;1&rdquo;,&ldquo;<em>score&rdquo;:1.0, &ldquo;</em>source&rdquo; : {</p>

<pre><code>"name" : "Tokyo St",
"pin" : {
    "location" : {
        "lat" : 35.68,
        "lon" : 139.76
    }
}
</code></pre>

<p>}}]}}
```</p>

<h4>範囲(矩形)</h4>

<p>左上:35.2/136.8 〜 右下:35.1/136.9 にあるデータを検索します。緯度は上(北)の方が値が大きくなるので、上下関係に注意が必要です。</p>

<p>```sh
curl -XPOST &lsquo;<a href="http://localhost:9200/myvenues/venue/_search">http://localhost:9200/myvenues/venue/_search</a>&rsquo; -d &lsquo;{</p>

<pre><code>"query": {
    "filtered" : {
        "query" : {
            "match_all" : {}
        },
        "filter" : {
            "geo_bounding_box" : {
                "venue.pin" : {
                    "top_left" : {
                        "lat" : 35.2,
                        "lon" : 136.8
                    },
                    "bottom_right" : {
                        "lat" : 35.1,
                        "lon" : 136.9
                    }
                }
            }
        }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<h5>結果</h5>

<p>Nagoya St だけがヒットしました。</p>

<p>```javascript
{&ldquo;took&rdquo;:0,&ldquo;timed_out&rdquo;:false,&ldquo;<em>shards&rdquo;:{&ldquo;total&rdquo;:5,&ldquo;successful&rdquo;:5,&ldquo;failed&rdquo;:0},&ldquo;hits&rdquo;:{&ldquo;total&rdquo;:1,&ldquo;max_score&rdquo;:1.0,&ldquo;hits&rdquo;:[{&ldquo;</em>index&rdquo;:&ldquo;myvenues&rdquo;,&ldquo;<em>type&rdquo;:&ldquo;venue&rdquo;,&ldquo;</em>id&rdquo;:&ldquo;2&rdquo;,&ldquo;<em>score&rdquo;:1.0, &ldquo;</em>source&rdquo; : {</p>

<pre><code>"name" : "Nagoya St",
"pin" : {
    "location" : {
        "lat" : 35.17,
        "lon" : 136.88
    }
}
</code></pre>

<p>}}]}}
```</p>

<h4>範囲(多角形)</h4>

<p>任意の多角形領域にあるデータを検索します。</p>

<p>ここでは GeoJSON 互換の記述方式で書いてます。経度が先なので注意。
今までのような lat: lon: の配列でもかけますが、 GeoJSON 便利なので。</p>

<p>```sh
curl -XPOST &lsquo;<a href="http://localhost:9200/myvenues/venue/_search">http://localhost:9200/myvenues/venue/_search</a>&rsquo; -d &lsquo;{</p>

<pre><code>"query": {
    "filtered" : {
        "query" : {
            "match_all" : {}
        },
        "filter" : {
            "geo_polygon" : {
                "venue.pin" : {
                    "points" : [
                        [139.7, 35.7],  // 経度が先！
                        [139.8, 35.7],
                        [139.8, 35.6],
                        [139.7, 35.6],
                        [139.7, 35.7]
                    ]
                }
            }
        }
    }
}
</code></pre>

<p>}&lsquo;
```</p>

<h5>結果</h5>

<p>Tokyo St だけがヒットしました。</p>

<p>```javascript
{&ldquo;took&rdquo;:0,&ldquo;timed_out&rdquo;:false,&ldquo;<em>shards&rdquo;:{&ldquo;total&rdquo;:5,&ldquo;successful&rdquo;:5,&ldquo;failed&rdquo;:0},&ldquo;hits&rdquo;:{&ldquo;total&rdquo;:1,&ldquo;max_score&rdquo;:1.0,&ldquo;hits&rdquo;:[{&ldquo;</em>index&rdquo;:&ldquo;myvenues&rdquo;,&ldquo;<em>type&rdquo;:&ldquo;venue&rdquo;,&ldquo;</em>id&rdquo;:&ldquo;1&rdquo;,&ldquo;<em>score&rdquo;:1.0, &ldquo;</em>source&rdquo; : {</p>

<pre><code>"name" : "Tokyo St",
"pin" : {
    "location" : {
        "lat" : 35.68,
        "lon" : 139.76
    }
}
</code></pre>

<p>}}]}}
```</p>

<p>(ポリゴンの座標群が、右回りじゃないとダメかな？と思って恐る恐る左回りにしてみたら、問題なく検索できました！)</p>

<h2>まとめ</h2>

<p>最初 <code>geo_point</code> を明示的に指定しないといけないのに気づかなくてしばらくハマりましたが、それ意外はすんなりと動きました。</p>

<p>機能を試しただけでパフォーマンスなどは計測できていませんが、なんか使えそうな気はします。</p>

<p>位置情報関係の情報を探したい時は、公式サイトの GUIDE</p>

<ul>
<li><a href="http://www.elasticsearch.org/guide/">Reference Guide | Elasticsearch</a></li>
</ul>


<p>の検索バーで 「geo」で検索すると、有用な情報が得られます。</p>

<h2>参考</h2>

<ul>
<li><a href="http://www.elasticsearch.org/">Open Source Distributed Real Time Search &amp; Analytics | Elasticsearch</a></li>
<li><a href="http://www.elasticsearch.org/blog/geo-location-and-search/">Geo Location And Search | Blog | Elasticsearch</a></li>
<li><a href="http://www.elasticsearchtutorial.com/spatial-search-tutorial.html">Spatial Search ElasticSearch tutorial &ndash; ElasticSearch Tutorial.com</a></li>
<li><a href="http://stackoverflow.com/questions/16113439/elasticsearch-geo-distance-filter-with-multiple-locations-in-array-possible">ElasticSearch geo distance filter with multiple locations in array &ndash; possible? &ndash; Stack Overflow</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
